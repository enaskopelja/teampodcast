{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.biorxiv.org/content/10.1101/2023.02.08.527623v1',\n",
       " 'https://www.biorxiv.org/content/10.1101/2022.11.04.515218v1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_messages_from_channel(channel_id, token):\n",
    "    client = slack_sdk.WebClient(token=token)\n",
    "    response = client.conversations_history(channel=channel_id)\n",
    "    # get all messages\n",
    "    messages = response['messages']\n",
    "    # get all urls\n",
    "    urls = []\n",
    "    for message in messages:\n",
    "        # extract urls from message using regex\n",
    "        urls += re.findall(r'(https?://[A-Za-z\\d\\/\\-\\.]+)', message['text'])\n",
    "    return list(set(urls))\n",
    "\n",
    "get_messages_from_channel('C04P4EWMHKM', token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://faas-ams3-2a2df116.doserverless.co/api/v1/web/fn-c5c8b0ac-65ad-4431-a584-56e7b664e9a6/slack/post_podcast'\n",
    "data = {\n",
    "    \"podcast_url\" : \"https://storage.googleapis.com/team-podcast/2023/2/10/23_53_36.mp3\",\n",
    "    \"podcast_intro\" : \"This is a test podcast\",\n",
    "    \"output_file\" : \"Cradle Bio - 2023 - Week 5.mp3\"\n",
    "}\n",
    "\n",
    "r = requests.post(url, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gpt-index\n",
      "  Downloading gpt_index-0.4.1.tar.gz (122 kB)\n",
      "\u001b[K     |████████████████████████████████| 122 kB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain\n",
      "  Downloading langchain-0.0.82-py3-none-any.whl (228 kB)\n",
      "\u001b[K     |████████████████████████████████| 228 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gpt-index) (4.19.2)\n",
      "Requirement already satisfied: tenacity<8.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gpt-index) (8.0.1)\n",
      "Requirement already satisfied: dataclasses-json in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gpt-index) (0.5.7)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gpt-index) (1.4.2)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (699 kB)\n",
      "\u001b[K     |████████████████████████████████| 699 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openai>=0.26.4\n",
      "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gpt-index) (1.22.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai>=0.26.4->gpt-index) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai>=0.26.4->gpt-index) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai>=0.26.4->gpt-index) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (2021.10.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->gpt-index) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->gpt-index) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->gpt-index) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->gpt-index) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->gpt-index) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->gpt-index) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->gpt-index) (2.1.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json->gpt-index) (0.7.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json->gpt-index) (3.15.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json->gpt-index) (1.5.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->gpt-index) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json->gpt-index) (4.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json->gpt-index) (0.4.3)\n",
      "Requirement already satisfied: PyYAML<7,>=6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain->gpt-index) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain->gpt-index) (1.4.35)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain->gpt-index) (1.9.0)\n",
      "Collecting tenacity<8.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->gpt-index) (8.1.3)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->gpt-index) (2022.4.24)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging->marshmallow<4.0.0,>=3.3.0->dataclasses-json->gpt-index) (3.0.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->gpt-index) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->gpt-index) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hmvanrossum/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.1->pandas->gpt-index) (1.16.0)\n",
      "Collecting blobfile>=2\n",
      "  Downloading blobfile-2.0.1-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.20\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycryptodomex~=3.8\n",
      "  Downloading pycryptodomex-3.17-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml~=4.9\n",
      "  Using cached lxml-4.9.2.tar.gz (3.7 MB)\n",
      "Requirement already satisfied: filelock~=3.0 in /Users/hmvanrossum/Library/Python/3.10/lib/python/site-packages (from blobfile>=2->tiktoken->gpt-index) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers->gpt-index) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers->gpt-index) (0.7.0)\n",
      "Using legacy 'setup.py install' for lxml, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: gpt-index, openai\n",
      "  Building wheel for gpt-index (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gpt-index: filename=gpt_index-0.4.1-py3-none-any.whl size=187252 sha256=19478826d8f707dce57f226f4909e4f59527845ed1b33e9f5f77555150808c32\n",
      "  Stored in directory: /Users/hmvanrossum/Library/Caches/pip/wheels/95/58/ba/14f5ce5d0a6f5a8d8ea7c17f58490e60f28d81c838d3ad31d3\n",
      "  Building wheel for openai (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67596 sha256=f727fcd95322cbf8ebc978b6b47deb8a97158b7fc41572aa3013b23d8d2ad6ee\n",
      "  Stored in directory: /Users/hmvanrossum/Library/Caches/pip/wheels/17/e0/3d/e7f547caa758526c1a066c1fdfa4995877ef34ea0e7367010e\n",
      "Successfully built gpt-index openai\n",
      "Installing collected packages: requests, pycryptodomex, lxml, tenacity, joblib, blobfile, tiktoken, openai, nltk, langchain, gpt-index\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "    Running setup.py install for lxml ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.18.1\n",
      "    Uninstalling openai-0.18.1:\n",
      "      Successfully uninstalled openai-0.18.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.8.1 requires click<8.1,>=7.0, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
      "Successfully installed blobfile-2.0.1 gpt-index-0.4.1 joblib-1.2.0 langchain-0.0.82 lxml-4.9.2 nltk-3.8.1 openai-0.26.5 pycryptodomex-3.17 requests-2.28.2 tenacity-8.1.0 tiktoken-0.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai_token = os.getenv('OPENAI_TOKEN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
